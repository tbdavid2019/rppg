#!/usr/bin/env python3
"""
rPPG Heart Rate Estimation using OpenCV and POS algorithm
"""
import os
os.environ["GRADIO_ANALYTICS_ENABLED"] = "False"

import gradio as gr
import cv2
import numpy as np
import matplotlib.pyplot as plt
from scipy import signal
from scipy.fft import fft, fftfreq
import tempfile
import time

def process_video(video_path, method, window, step, min_bpm, max_bpm, conf, progress=None):
    import time
    from tqdm import tqdm
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return "Error: Unable to open video file.", None, None

    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps if fps > 0 else 0
    
    if not fps or fps <= 1e-3:
        fps = 30.0
    
    win_frames = int(window * fps)
    step_frames = int(step * fps)
    
    print(f"Video info: {total_frames} frames, {fps:.2f} fps, {duration:.1f}s duration")
    print(f"Processing parameters: window={window}s ({win_frames} frames), step={step}s ({step_frames} frames)")
    
    # Estimate processing time
    estimated_chunks = max(1, (total_frames - win_frames) // step_frames + 1)
    print(f"Estimated {estimated_chunks} processing chunks")
    
    # Reliable face detection using OpenCV
    print("üîç Using reliable OpenCV face detection...")
    if progress:
        progress(0.05, "üîç ‰ΩøÁî® OpenCV Ê™¢Ê∏¨‰∫∫Ëáâ‰∏≠...")
    
    # ËºâÂÖ• OpenCV ‰∫∫ËáâÊ™¢Ê∏¨Âô®
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    
    face_detected = False
    face_found_at_frame = None
    checked_frames = 0
    
    # ÊåÅÁ∫åÊ™¢Ê∏¨Áõ¥Âà∞ÊâæÂà∞‰∫∫ËáâÁÇ∫Ê≠¢ÔºàÊØèÈöî15ÂπÄÊ™¢Êü•‰∏ÄÊ¨°‰ª•ÊèêÈ´òÊ∫ñÁ¢∫ÊÄßÔºâ
    for i in range(0, total_frames, 15):
        cap.set(cv2.CAP_PROP_POS_FRAMES, i)
        ret, frame = cap.read()
        if ret:
            # ‰ΩøÁî® OpenCV ÈÄ≤Ë°å‰∫∫ËáâÊ™¢Ê∏¨
            try:
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                
                # Â§öÁ®ÆÂèÉÊï∏ÁµÑÂêà‰æÜÊèêÈ´òÊ™¢Ê∏¨Áéá
                param_sets = [
                    {"scaleFactor": 1.1, "minNeighbors": 5, "minSize": (30, 30)},
                    {"scaleFactor": 1.05, "minNeighbors": 3, "minSize": (20, 20)},
                    {"scaleFactor": 1.2, "minNeighbors": 6, "minSize": (40, 40)},
                ]
                
                faces_found = False
                for params in param_sets:
                    faces = face_cascade.detectMultiScale(gray, **params)
                    if len(faces) > 0:
                        faces_found = True
                        face_detected = True
                        face_found_at_frame = i
                        time_stamp = i / fps
                        
                        # Á´ãÂç≥È°ØÁ§∫ Gradio ÊèêÁ§∫
                        if progress:
                            progress(0.1, f"‚úÖ Âú®Á¨¨ {i} ÂπÄ ({time_stamp:.1f}Áßí) Ê™¢Ê∏¨Âà∞ {len(faces)} ÂÄã‰∫∫ËáâÔºÅÈñãÂßãËôïÁêÜ...")
                        print(f"‚úÖ Face detected at frame {i} ({time_stamp:.1f}s)! Found {len(faces)} faces")
                        break
                
                if faces_found:
                    break
                    
            except Exception as e:
                print(f"OpenCV Ê™¢Ê∏¨ÈåØË™§: {e}")
                pass
        
        checked_frames += 1
        # Êõ¥Êñ∞Ê™¢Ê∏¨ÈÄ≤Â∫¶
        if progress and checked_frames % 20 == 0:  # ÊØèÊ™¢Êü•20ÂπÄÊõ¥Êñ∞‰∏ÄÊ¨°ÈÄ≤Â∫¶
            detection_progress = 0.05 + min((i / total_frames) * 0.05, 0.05)
            current_time = i / fps
            progress(detection_progress, f"üîç Ê™¢Ê∏¨‰∫∫Ëáâ‰∏≠... Â∑≤Ê™¢Êü•Âà∞ {current_time:.1f}Áßí ({checked_frames} Ê¨°Ê™¢Êü•)")
    
    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reset to beginning
    
    if not face_detected:
        warning_msg = "‚ö†Ô∏è Ë≠¶ÂëäÔºöÊï¥ÂÄãÂΩ±Áâá‰∏≠Êú™Ê™¢Ê∏¨Âà∞‰∫∫ËáâÔºÅ"
        print("‚ö†Ô∏è  WARNING: No faces detected in entire video!")
        print("üí° This video may not contain detectable faces. Processing will continue but will likely fail.")
        if progress:
            progress(0.1, warning_msg)
    else:
        success_msg = f"‚úÖ ‰∫∫ËáâÊ™¢Ê∏¨ÊàêÂäü - Âú®Á¨¨ {face_found_at_frame} ÂπÄ ({face_found_at_frame/fps:.1f}Áßí) ÊâæÂà∞‰∫∫Ëáâ"
        print("‚úÖ Face detection working - processing should succeed")
        if progress:
            progress(0.15, success_msg)

    # Map string methods to Method enum
    method_map = {
        "pos": Method.POS,
        "chrom": Method.CHROM,
        "g": Method.G,
        "vitallens": Method.VITALLENS
    }
    
    rppg_method = method_map.get(method.lower(), Method.POS)
    
    # Create VitalLens instance with optimized parameters
    rppg = VitalLens(
        method=rppg_method,
        detect_faces=True,           # ÂïüÁî®‰∫∫ËáâÊ™¢Ê∏¨
        estimate_rolling_vitals=False,  # ÂÅúÁî®ÊªæÂãï‰º∞Ë®à‰ª•ÊèêÈ´òÁ©©ÂÆöÊÄß
        roi_method="MEDIAN",         # ‰ΩøÁî®‰∏≠‰ΩçÊï∏ ROI ÊñπÊ≥ï
        mode="BATCH"                 # ‰ΩøÁî®ÊâπËôïÁêÜÊ®°Âºè
    )

    # Process video in chunks instead of loading all frames
    ts, hr, cf = [], [], []
    frame_buffer = []
    frame_idx = 0
    processed_chunks = 0
    
    # Progress bar for console
    pbar = tqdm(total=total_frames, desc="Processing video", unit="frames")
    
    start_time = time.time()
    
    while True:
        ok, frame = cap.read()
        if not ok:
            break
            
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame_buffer.append(rgb)
        frame_idx += 1
        
        # Update progress
        pbar.update(1)
        if progress:
            progress(frame_idx / total_frames, f"Reading frames: {frame_idx}/{total_frames}")
        
        # Process when we have enough frames for a window and it's time to process
        if len(frame_buffer) >= win_frames and (frame_idx % step_frames == 0 or frame_idx == total_frames):
            try:
                # Use the last window_frames for processing
                window_frames = frame_buffer[-win_frames:] if len(frame_buffer) >= win_frames else frame_buffer
                video_chunk = np.array(window_frames)
                
                # Process this chunk
                chunk_results = rppg(video_chunk, fps=fps)
                
                # Extract results
                if chunk_results and len(chunk_results) > 0:
                    result = chunk_results[-1]  # Take the last (most recent) result
                    
                    # Try different possible key names
                    hr_value = None
                    conf_value = 0.0
                    
                    if isinstance(result, dict):
                        # Try common key names for heart rate
                        for hr_key in ['hr', 'heart_rate', 'bpm', 'pulse']:
                            if hr_key in result:
                                hr_value = result[hr_key]
                                break
                        
                        # Try common key names for confidence
                        for conf_key in ['confidence', 'conf', 'reliability', 'quality']:
                            if conf_key in result:
                                conf_value = result[conf_key]
                                break
                    
                    if hr_value is not None and conf_value >= conf:
                        t_sec = frame_idx / fps
                        ts.append(t_sec)
                        hr.append(float(hr_value))
                        cf.append(float(conf_value))
                        print(f"‚úÖ Found HR: t={t_sec:.1f}s, HR={hr_value:.1f}, conf={conf_value:.3f}")
                        
                        # Gradio Êõ¥Êñ∞ÔºöÈ°ØÁ§∫ÊâæÂà∞ÁöÑÂøÉÁéá
                        if progress:
                            progress_val = min(processed_chunks / estimated_chunks, 0.95)
                            progress(progress_val, f"üíì ÊâæÂà∞ÂøÉÁéá: {hr_value:.1f} BPM (Á¨¨ {processed_chunks} ÊÆµ)")
                            
                    elif processed_chunks % 50 == 0:  # Print status every 50 chunks
                        face_status = "Êúâ‰∫∫Ëáâ" if len(chunk_results) > 0 else "ÁÑ°‰∫∫Ëáâ"
                        print(f"‚ö†Ô∏è  No valid HR found in chunk {processed_chunks}. Face detected: {len(chunk_results) > 0}")
                        
                        # Gradio Êõ¥Êñ∞ÔºöÈ°ØÁ§∫ËôïÁêÜÁãÄÊÖã
                        if progress:
                            progress_val = min(processed_chunks / estimated_chunks, 0.95)
                            progress(progress_val, f"‚ö†Ô∏è ËôïÁêÜ‰∏≠... Á¨¨ {processed_chunks} ÊÆµ ({face_status})")
                            
                else:
                    if processed_chunks % 50 == 0:  # Print status every 50 chunks
                        print(f"‚ùå No results from chunk {processed_chunks}. Possible face detection failure.")
                        
                        # Gradio Êõ¥Êñ∞ÔºöÈ°ØÁ§∫Ê™¢Ê∏¨Â§±Êïó
                        if progress:
                            progress_val = min(processed_chunks / estimated_chunks, 0.95)
                            progress(progress_val, f"‚ùå Á¨¨ {processed_chunks} ÊÆµÔºö‰∫∫ËáâÊ™¢Ê∏¨ÂèØËÉΩÂ§±Êïó")
                
                # Êó©ÊúüÂÅúÊ≠¢Ê©üÂà∂ÔºöÂ¶ÇÊûúÂâçÈù¢ÁöÑ chunks ÈÉΩÊ≤íÊúâÊâæÂà∞ÊúâÊïàÊ∏¨ÈáèÂÄº
                if processed_chunks >= 10 and len(hr) == 0:
                    stop_msg = f"üõë ÊèêÂâçÂÅúÊ≠¢ÔºöÂâç {processed_chunks+1} ÊÆµÈÉΩÊú™ÊâæÂà∞ÊúâÊïàÊ∏¨ÈáèÂÄº"
                    print(f"\nüõë EARLY STOP: No valid measurements found in first {processed_chunks+1} chunks.")
                    print("üí° This indicates the video is not suitable for rPPG analysis.")
                    print("üìã Suggestions:")
                    print("   - Ensure clear, front-facing face visibility")
                    print("   - Good lighting conditions") 
                    print("   - Minimal head movement")
                    print("   - Try a different video")
                    
                    # Gradio Êõ¥Êñ∞ÔºöÈ°ØÁ§∫ÂÅúÊ≠¢ÂéüÂõ†
                    if progress:
                        progress(0.5, f"{stop_msg} - ÂΩ±ÁâáÂèØËÉΩ‰∏çÈÅ©ÂêàÂàÜÊûê")
                    break
                        
                processed_chunks += 1
                elapsed = time.time() - start_time
                if processed_chunks > 0:
                    avg_time_per_chunk = elapsed / processed_chunks
                    remaining_chunks = estimated_chunks - processed_chunks
                    eta = remaining_chunks * avg_time_per_chunk
                    print(f"Processed chunk {processed_chunks}/{estimated_chunks}, ETA: {eta:.1f}s")
                    
                    # ÂÆöÊúüÊõ¥Êñ∞ Gradio ÈÄ≤Â∫¶ÔºàÊØè10ÂÄãchunkÊàñÊØè20ÁßíÊõ¥Êñ∞‰∏ÄÊ¨°Ôºâ
                    if processed_chunks % 10 == 0 or (processed_chunks > 0 and processed_chunks % max(1, int(20 / avg_time_per_chunk)) == 0):
                        progress_val = min(processed_chunks / estimated_chunks, 0.95)
                        hr_count = len(hr)
                        if progress:
                            if hr_count > 0:
                                latest_hr = hr[-1] if hr else 0
                                progress(progress_val, f"üíì Â∑≤ÊâæÂà∞ {hr_count} ÂÄãÂøÉÁéáÊ∏¨ÈáèÂÄº (ÊúÄÊñ∞: {latest_hr:.1f} BPM) - ÈÄ≤Â∫¶: {processed_chunks}/{estimated_chunks}")
                            else:
                                progress(progress_val, f"üîÑ ËôïÁêÜ‰∏≠... {processed_chunks}/{estimated_chunks} ÊÆµ (È†ê‰º∞Ââ©È§ò: {eta:.0f}Áßí)")
                
            except Exception as e:
                print(f"Error processing chunk at frame {frame_idx}: {e}")
                continue
            
            # Keep only recent frames to manage memory
            if len(frame_buffer) > win_frames * 2:
                frame_buffer = frame_buffer[-win_frames:]
    
    pbar.close()
    cap.release()
    
    total_time = time.time() - start_time
    print(f"Processing completed in {total_time:.1f}s, extracted {len(hr)} heart rate measurements")
    
    # Analysis and suggestions
    if len(hr) == 0:
        print("\n‚ö†Ô∏è  WARNING: No heart rate measurements extracted!")
        print("üí° Possible causes:")
        print("   1. No face detected in the video")
        print("   2. Poor lighting conditions")
        print("   3. Face too small or partially occluded")
        print("   4. Excessive head movement")
        print("   5. Video quality too low")
        print("   6. Confidence threshold too high")
        print("\nüîß Suggestions:")
        print("   - Ensure the face is clearly visible and well-lit")
        print("   - Try lowering the confidence threshold to 0.0")
        print("   - Use a shorter video segment for testing")
        print("   - Ensure minimal head movement")
    elif len(hr) < 5:
        print(f"\n‚ö†Ô∏è  WARNING: Only {len(hr)} measurements extracted from {processed_chunks} chunks")
        print("üí° This might indicate intermittent face detection issues")
    else:
        print(f"\n‚úÖ Successfully extracted {len(hr)} measurements from {processed_chunks} chunks")
        print(f"üìä Success rate: {len(hr)/processed_chunks*100:.1f}%")

    if not hr:
        return "No heart rate data extracted.", None, None

    # Create CSV
    csv_content = "time_sec,hr_bpm,confidence\n"
    for a, b, c in zip(ts, hr, cf):
        csv_content += f"{a:.2f},{b:.2f},{c:.3f}\n"

    # Create plot
    plt.figure(figsize=(10,4))
    plt.plot(ts, hr)
    plt.xlabel("Time (s)")
    plt.ylabel("Heart Rate (bpm)")
    plt.title("Estimated HR from rPPG (video)")
    plt.grid(True)
    plt.tight_layout()
    
    # Save plot to temp file
    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
        plt.savefig(tmp.name)
        plot_path = tmp.name
    
    plt.close()

    return f"Processed {len(hr)} data points.", plot_path, csv_content

def gradio_interface(video, method, window, step, min_bpm, max_bpm, conf, progress=gr.Progress()):
    if video is None:
        return "Please upload a video file.", None, None
    
    # video is a file object from Gradio, get the file path as string
    video_path = str(video.name) if hasattr(video, 'name') else str(video)
    
    # Ensure it's an absolute path
    if not os.path.isabs(video_path):
        video_path = os.path.abspath(video_path)
    
    try:
        # Pass progress callback to process_video
        def progress_callback(pct, msg):
            progress(pct, desc=msg)
        
        message, plot_path, csv_content = process_video(video_path, method, window, step, min_bpm, max_bpm, conf, progress_callback)
        if plot_path:
            return message, plot_path, csv_content
        else:
            return message, None, None
    except Exception as e:
        return f"Error processing video: {str(e)}", None, None

# Gradio interface
with gr.Blocks() as demo:
    gr.Markdown("# rPPG Heart Rate Estimation from Video")
    gr.Markdown("Upload a video file to estimate heart rate using rPPG methods.")
    
    with gr.Row():
        video_input = gr.File(label="Upload Video", file_types=[".mp4", ".mkv", ".mov", ".avi"])
    
    with gr.Row():
        method = gr.Dropdown(["pos", "chrom", "g"], value="pos", label="Method")
        window = gr.Number(value=10.0, label="Window (seconds)")
        step = gr.Number(value=2.0, label="Step (seconds)")
    
    with gr.Row():
        min_bpm = gr.Number(value=42, label="Min BPM")
        max_bpm = gr.Number(value=180, label="Max BPM")
        conf = gr.Number(value=0.0, label="Confidence Threshold (0.0 = accept all)")
    
    submit_btn = gr.Button("Process Video")
    
    output_text = gr.Textbox(label="Status")
    output_plot = gr.Image(label="Heart Rate Plot")
    output_csv = gr.Textbox(label="CSV Data", lines=10)
    
    submit_btn.click(
        gradio_interface,
        inputs=[video_input, method, window, step, min_bpm, max_bpm, conf],
        outputs=[output_text, output_plot, output_csv]
    )

if __name__ == "__main__":
    demo.launch()